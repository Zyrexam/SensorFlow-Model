{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d6f14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sensorflow_model.dataset import get_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4599a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_with_saved_stats(X, stats_path=\"../normalization.json\"):\n",
    "    with open(stats_path) as f:\n",
    "        stats = json.load(f)\n",
    "\n",
    "    mean = np.array(stats[\"mean\"])\n",
    "    std = np.array(stats[\"std\"])\n",
    "\n",
    "    # Apply normalization\n",
    "    X_flat = X.reshape(-1, X.shape[-1])\n",
    "    X_norm = ((X_flat - mean) / std).reshape(X.shape)\n",
    "    return X_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ff15d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sensorflow_model.dataset import create_sliding_windows, load_csv, normalize_features\n",
    "\n",
    "\n",
    "def get_dataset(filepath, window_size=20, stride=5, normalize=True, use_saved_stats=False, stats_path=\"../normalization.json\"):\n",
    "    df = load_csv(filepath)\n",
    "    X, y = create_sliding_windows(df, window_size, stride)\n",
    "\n",
    "    if normalize:\n",
    "        if use_saved_stats:\n",
    "            X = normalize_with_saved_stats(X, stats_path)\n",
    "        else:\n",
    "            X, _ = normalize_features(X)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8bc400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataset(folder_path):\n",
    "    X_all, y_all = [], []\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".csv\"):\n",
    "            filepath = os.path.join(folder_path, file)\n",
    "\n",
    "            # Load with test-time normalization (using training stats)\n",
    "            X, y = get_dataset(filepath, window_size=20, stride=5, normalize=True, use_saved_stats=True)\n",
    "\n",
    "            X_all.append(X)\n",
    "            y_all.append(y)\n",
    "\n",
    "    return np.concatenate(X_all), np.concatenate(y_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3dfdd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 46 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Load model\n",
    "model = keras.models.load_model(\"../final_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d8af5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load test data\n",
    "x_test, y_test = load_test_dataset(\"../TestData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4a73982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0078 - loss: 6.3882 \n",
      "\n",
      " Test Accuracy: 1.59%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Evaluate\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(f\"\\n Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b41469f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ACTIVITY_CLASSES = {\n",
    "    0: \"Sitting + Typing on Desk\",\n",
    "    1: \"Sitting + Taking Notes\", \n",
    "    2: \"Standing + Writing on Whiteboard\",\n",
    "    3: \"Standing + Erasing Whiteboard\",\n",
    "    4: \"Sitting + Talking + Waving Hands\",\n",
    "    5: \"Standing + Talking + Waving Hands\",\n",
    "    6: \"Sitting + HeadNodding\",\n",
    "    7: \"Sitting + Drinking Water\",\n",
    "    8: \"Sitting + Drinking Coffee\",\n",
    "    9: \"Standing + Drinking Water\",\n",
    "    10: \"Standing + Drinking Coffee\",\n",
    "    11: \"Scrolling on Phone\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "544b004b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "         Sitting + Typing on Desk       0.00      0.00      0.00       239\n",
      "           Sitting + Taking Notes       0.00      0.00      0.00       115\n",
      " Standing + Writing on Whiteboard       0.00      0.00      0.00         0\n",
      "    Standing + Erasing Whiteboard       0.03      0.06      0.04       263\n",
      " Sitting + Talking + Waving Hands       0.00      0.00      0.00         0\n",
      "Standing + Talking + Waving Hands       0.00      0.00      0.00       241\n",
      "            Sitting + HeadNodding       0.00      0.00      0.00         0\n",
      "         Sitting + Drinking Water       0.00      0.01      0.01       189\n",
      "        Sitting + Drinking Coffee       0.00      0.00      0.00       271\n",
      "        Standing + Drinking Water       0.00      0.00      0.00       139\n",
      "       Standing + Drinking Coffee       0.14      0.06      0.09       161\n",
      "               Scrolling on Phone       0.01      0.00      0.01       205\n",
      "\n",
      "                         accuracy                           0.02      1823\n",
      "                        macro avg       0.01      0.01      0.01      1823\n",
      "                     weighted avg       0.02      0.02      0.01      1823\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "labels = list(ACTIVITY_CLASSES.keys())\n",
    "target_names = list(ACTIVITY_CLASSES.values())\n",
    "\n",
    "print(classification_report(y_test, y_pred_labels, labels=labels, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce545d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
